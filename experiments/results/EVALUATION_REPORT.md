# Comprehensive Benchmark Evaluation Report

**Generated:** 2026-02-17 22:58:44

## Benchmarks Overview

| Benchmark ID | Description | Safety Properties | Test Cases |
|--------------|-------------|-------------------|------------|
| 01_speculative_stream | Speculative Stream Controller | 4 | Hypothesis-based |
| 02_producer_consumer | Bounded Buffer (Producer-Consumer) | 5 | Hypothesis-based |
| 03_concurrent_cache | Thread-Safe LRU Cache | 5 | Hypothesis-based |
| 04_rate_limiter | Token Bucket Rate Limiter | 5 | Hypothesis-based |

## Property Test Results

### 01_speculative_stream

- **Total Tests:** 3
- **Passed:** 3 ✅
- **Failed:** 0 ❌
- **Errors:** 0 ⚠️
- **Execution Time:** 0.83s

### 02_producer_consumer

- **Total Tests:** 4
- **Passed:** 4 ✅
- **Failed:** 0 ❌
- **Errors:** 0 ⚠️
- **Execution Time:** 0.59s

### 03_concurrent_cache

- **Total Tests:** 5
- **Passed:** 5 ✅
- **Failed:** 0 ❌
- **Errors:** 0 ⚠️
- **Execution Time:** 0.50s

### 04_rate_limiter

- **Total Tests:** 6
- **Passed:** 6 ✅
- **Failed:** 0 ❌
- **Errors:** 0 ⚠️
- **Execution Time:** 18.91s

## Summary Statistics

**Overall Property Test Pass Rate:** 18/18 (100.0%)

## Benchmark Characteristics

All benchmarks test **concurrent correctness properties**:

1. **Safety Properties:** Invariants that must hold in all states
2. **Liveness Properties:** Guarantees of progress
3. **Atomicity:** Operations complete without interference
4. **Consistency:** State remains valid under concurrent access

## Testing Methodology

- **Framework:** Hypothesis (property-based testing)
- **Strategy:** Randomized test case generation
- **Concurrency:** Multi-threaded stress testing
- **Verification:** Formal property checking

## Next Steps

To run full comparative evaluation with LLM methods:

```bash
# Run Formal-SDD on all benchmarks
python experiments/run_all.py --method formal_sdd

# Run Baseline 1 (Zero-shot Direct Synthesis)
python experiments/run_all.py --method baseline_1

# Run Baseline 2 (Test-Driven Development)
python experiments/run_all.py --method baseline_2

# Generate comparative analysis
python experiments/analysis/calc_metrics.py
```

---

**Report generated by:** Formal-SDD Evaluation Framework